# V4 notes
# v4 all on this branch "develop-v4"

v4 Scope (prioritised)

Model Toggle (dev)

Add a UI toggle to switch between models at runtime (e.g., gpt-4o-mini, gpt-4o, gpt-3.5-turbo, mock).

Plumb model to backend via request body and allow override via query ?model=.

Persist selection in localStorage.

Show tiny cost hint per model in the toggle menu.

Mode-Tagged Replies

Every assistant message rendered with a fixed prefix derived from the active mode:
JD → [JD]:, GW → [GW]:, MGS → [MGS]:, BTC → [BTC]:

Implement as frontend decoration, not a prompt instruction (prevents model wasting tokens).

Optionally add a small colored badge in the UI aligned to the prefix.

Shareable Online Demo

Backend: keep Cloudflare Worker; add a staging route (/chat, /health), CORS allow your demo origin.

Frontend (web): deploy to Vercel/Netlify/Cloudflare Pages with EXPO_PUBLIC_API_URL pointing to the Worker URL.

Add simple access gate for staging (single env token via query ?k=… or basic password prompt) to avoid random traffic.

Produce a short “share” URL and a minimal “demo instructions” section.

Funding & Spend Control

Hard cap remains $5/month.

Add server-side limiter: N requests/15min per IP, message length cap, and per-session token ceiling.

Add a Model “mock” option to test UI without cost.

Optional: display a Lightning QR (donations) and a “budget left” indicator (est. from your worker log counters).

Security & Prompt Hardening

System prompts are server-side only; never expose verbatim in responses.

Sanitize and clamp input: strip control chars, 4–8k char max.

Guard against prompt injection: refuse tool/URL execution; disable markdown HTML by default in render.

Add CSP in web deploy and lock CORS to your domains.

Rate limit (above), timeouts + abort controllers, and graceful error banners.

(Carryover) Readability Polish

Preserve \n, wrap long tokens/URLs, never clip text.

Word-boundary streaming buffer (flush on whitespace every ~33–50ms).

Auto-scroll to latest message.

CRT ON/OFF does not affect wrapping/clipping; subtle text shadow when ON.

Keep debug panel dev-only (EXPO_PUBLIC_DEBUG_MODE=1).

---

Implementation Notes
A) Model Toggle

UI: ModelToggle.tsx near MODE/CRT/THEME.

Choices: gpt-4o-mini (cheap), gpt-4o (quality), gpt-3.5-turbo (ultra-cheap), mock (free).

Frontend: store in localStorage and include in body:

body = { mode, messages, options: { model } }


Backend: read options.model ?? env.DEFAULT_MODEL. If mock, stream canned tokens. Enforce allowlist.

B) Mode-Tagged Replies

Don’t ask the model to add tags. In the message renderer:

const tag = mode === 'JD' ? '[JD]: ' : mode === 'BTC' ? '[BTC]: ' : mode === 'GW' ? '[GW]: ' : '[MGS]: ';
return <span><strong>{tag}</strong>{renderedText}</span>;


Optional badge color per theme.

C) Online Demo

Worker: add CORS for your demo origin; optional X-DEMO-KEY header check.

Frontend deploy:

Vercel/Netlify project → set EXPO_PUBLIC_API_URL to Worker URL.

Add EXPO_PUBLIC_DEBUG_MODE=0 for demo.

Share link: put in docs/demo.md with 3 bullet “how to try” steps.

D) Spend Controls

Worker counters: simple in-memory map (per-instance) with IP bucket; log usage totals.

Cap tokens per reply (max_output_tokens) and early-stop on budget hit.

Research mode default OFF; warning tooltip on toggle.

E) Security

Prompt composer never includes user-provided files verbatim without sanitization.

Escape rendered text; disable inline HTML.

Add basic Sentry (or console logging) for frontend errors; redact PII.

F) Readability

Styles for message:

white-space: pre-wrap;
word-break: break-word;
overflow-wrap: anywhere;
line-height: 1.35;
letter-spacing: .2px;
font-family: 'VT323', ui-monospace, Menlo, Consolas, 'Liberation Mono', monospace;


Word-buffer logic in streaming client (pending→flush on last whitespace).

Auto-scroll with ref.scrollTo({ top: scrollHeight, behavior: 'smooth' }).

Acceptance Criteria

Model Toggle: switching models immediately affects next reply; persisted across reload; “mock” produces deterministic sample stream.

Tagged Replies: all assistant messages show [JD]:|[BTC]:|[GW]:|[MGS]: prefix (not part of model text).

Demo Online: URL shared to a friend loads and chats; requests hit the Worker; CORS OK; optional access gate works.

Spend Controls: exceeding per-IP or per-session limits yields a friendly banner and disables send; budget logs visible in Worker.

Security: no HTML injection; long inputs get truncated with a notice; system prompts never echoed.

Readability: no clipping or truncation; newline preserved; auto-scroll reliable; CRT toggle doesn’t affect legibility.

---

# Run locally
npm run dev

# Web demo build (if needed)
cd apps/mobile && npm run build

# Deploy frontend (Vercel/Netlify/CF Pages) – set EXPO_PUBLIC_API_URL to Worker URL
# Deploy worker as 'staging' route – ensure CORS allowlist includes the demo origin

---

Suggested Issues for a Private GitHub Project

v4-001: Implement ModelToggle (frontend + backend allowlist, mock mode).

v4-002: Add mode-tag prefixes in renderer + badge color map.

v4-003: Deploy shareable demo (frontend to Vercel/Netlify; CORS on Worker; access gate).

v4-004: Add rate limits & per-session caps; “budget near cap” banner.

v4-005: Prompt hardening (sanitize input, clamp length, refuse tool/URL asks).

v4-006: Readability polish (wrap/newlines, buffer, auto-scroll, CRT shadow).

v4-007: Error UX (SSE retry, abort controller, clear error banners).

v4-008: Donation QR (Lightning) + “budget left” indicator (optional).

---

Prompt for Warp (copy-paste)

Start v4 (new branch) and tackle our top priorities: model toggle, tagged replies, shareable demo, spend controls, security, readability.

Branch -> git checkout -b develop-v4

Model Toggle

Add ModelToggle.tsx near MODE/CRT/THEME.

Models: gpt-4o-mini (cheap), gpt-4o (quality), gpt-3.5-turbo (ultra-cheap), mock (free).

Persist via localStorage. Send choice as options.model in chat body.

Backend: allowlist and default model. If mock, stream deterministic fake tokens.

Mode-Tagged Replies

Frontend-only prefix in renderer: [JD]:|[BTC]:|[GW]:|[MGS]: from current mode.

Optional colored badge. Do not ask model to add tags.

Shareable Demo

Deploy frontend to Vercel/Netlify with EXPO_PUBLIC_API_URL=<worker staging url>.

Worker: add CORS for the demo origin and an optional X-DEMO-KEY or ?k= guard.

Provide final share URL in docs/demo.md.

Funding/Spend Controls

Worker: per-IP rate limit + per-session message/token caps. Friendly banner when exceeded.

UI: “mock” model in ModelToggle to test with zero cost.

Security & Prompt Hardening

Clamp & sanitize input; refuse HTML; disable tool/URL execution.

Ensure system prompts never reflected to user.

Add simple CSP on web deploy.

Readability Polish (carryover)

Preserve \n, wrap long tokens; word-buffer streaming; auto-scroll; CRT shadow; dev-only debug.

Acceptance Criteria

As outlined in docs/v4-plan.md. Please add a short QA checklist to devlog.md and ensure CI stays green.